"The primary goal of the marketplace is to act as a comprehensive catalog and distribution point for deploying cloud services, whether they are developed internally (OWD components) or third-party services. It's designed to simplify discovery and consumption.      To help you quickly find a specific service amidst many, there are two main approaches:     *   **Search:** You can use the top search bar to look for services based on text. This searches across several attributes the platform uses to organize services: Name, Label, Summary, Content (like code or configuration), and Network Visibility.     *   **Filtering:** On the left-hand side, there's a filtering panel. Here, you can filter services based on their **Type** (whether they are "Internal" OWD components or "Third-party" added from the market) or their **Network Visibility** level (Public, Organization, or Project). This is useful for narrowing down the list based on broader characteristics before considering specifics."
"The platform uses a clear versioning strategy for services discovered and deployed via the marketplace. When you see a service listing with a version like 'v1' or 'v2', it actually represents a major version, such as 'v1.x.y'. Within each major version ('v1'), the platform automatically generates and manages minor and patch versions (like 'v1.2.3').      If you build a new service component that depends on another service component connected to 'v1' from the marketplace, the platform automatically updates your dependency in the `component.yaml` file to use the 'v1' major version. This means your dependent component will automatically utilize any minor or patch versions within that major release range (e.g., 'v1.2', 'v1.3', etc.).      So, if 'Service A' was initially 'v1.2' (connected to `v1` on the marketplace), and they subsequently released 'v1.3', the platform would automatically update your component's dependency to `v1` to leverage the 'v1.3' version without requiring you to manually change your configuration or redeploy your dependent service. This ensures your dependent service always uses the latest backward-compatible updates from the 'v1' major version."
"The marketplace offers two primary methods to help you efficiently discover and narrow down the list of available services: Search and Filter.      *   **Search:** You can use the search bar at the top of the marketplace interface. This allows you to search for text across several attributes of the services:         *   **Name:** Searches the service's official name.         *   **Label:** Looks for services with specific labels assigned to them, which can help organize services within teams or for specific applications.         *   **Content:** Searches within the service's overview, summary, and documentation.         *   **All:** Searches across all the above attributes simultaneously.         Utilizing search is great when you know part of the service name, a label it uses, or keywords from its description or documentation.      *   **Filter:** The left-hand side panel provides filtering options based on specific criteria. This is useful for categorizing services based on their characteristics:         *   **Type:** You can filter services by their origin or hosting location: "Internal" for services deployed within the platform, or "Third-party" for externally running services added to the marketplace.         *   **Network Visibility:** You can filter based on who the service is exposed to: "Public" (exposed externally), "Organization" (exposed across your entire organization), or "Project" (exposed only within your specific project).         Filtering is ideal when you know the general area the service comes from or its expected audience range, as it lets you limit the results to that category.      By combining searching and filtering, you can quickly navigate through potentially large numbers of services to reach the one you need within your organization's marketplace."
"This marketplace utilizes a intelligent "semantic-version-based intelligent routing" mechanism for this scenario. When you connect your component to a service from the marketplace, especially one that has undergone updates (like going from `v1` to `v1.1`, `v1.2`, etc.), the marketplace doesn't just provide separate connections for each version. Instead, it offers only one connection point per major version (e.g., `v1`). Crucially, if a service with a major version `v1` is running newer minor or patch versions (like `v1.5`), the system automatically routes traffic from your `v1` connected component to the latest available `v1.x` version (which would be `v1.5` in this example).      This ensures that your consuming component benefits automatically from backward-compatible updates and improvements without requiring you to change your connection configuration each time the service publisher releases a new minor version. You only need to establish the connection once to a given major version, and the platform handles routing to the specific latest version within that range."
"When you're facing a large number of services in the internal Marketplace and you know part of the service name or its usage intent, the best approach is to use the search functionality. The primary criterion for search results is the service's **Name**.      By searching by name, you'll get a list of services that match the text you entered. If there's only one service that matches, it will be uniquely identifiable in the list. This search by name is precise and efficient for locating services within your organization.      Once you click on a service card from the search results, you'll see a overview page with several key details provided *without* needing to browse through multiple tabs:     *   **Service Name:** This is the unique identifier for the service, based on its development namespace and project.     *   **Overview:** A brief description of the service provided by the developer.     *   **Definition File:** The file name of the service's definition, typically extracted from the `component.yaml` in the source code repository.     *   **API Definition:** If available, the definition of the service's API (e.g., OpenAPI specification for a REST service).     *   **Version:** The major version of the service (e.g., `v1`), indicating the API version.     *   **Type:** Whether it's a "Internal" service (networked internally) or a "External" service (exposed externally from the Marketplace).      These details at a glance allow you to quickly understand what the service is and its basic characteristics before you proceed to explore it further or create a connection to consume it."
"When you browse the Marketplace, versions are displayed based on the major version number. So, if the `InventoryCheck` service is available as both `v1.5` and the new `v2.0`, the Marketplace will primarily show two entries for `InventoryCheck`: one representing the `v1` major version, which will automatically update to `v1.5` (since `v1.5` is the latest version within the `v1` major release), and one representing the `v2` major version, which will show `v2.0`.      Crucially for your `OrderProcessing` service, which depends on `v1` of `InventoryCheck`, the platform utilizes semantic-version-based intelligent routing. When `InventoryCheck` `v1.5` (the new minor version within the `v1` major release) is deployed, the connection between your `OrderProcessing` service and the `InventoryCheck` `v1` service **will be automatically updated** to point to the `v1.5` version of `InventoryCheck`**. This happens without any manual configuration or intervention on your part. This ensures that your `OrderProcessing` service continues to consume the latest compatible version within the `v1` major release range. When `InventoryCheck` `v2.0` (a new major version) is deployed, you would need to update your `OrderProcessing` service's dependency to `v2` if you are ready to adopt the new major version."
"When you deploy a service component with an exposed endpoint, it gets automatically included in the Marketplace. This process is automatic upon deployment.      Once added, the Marketplace entry for your service will provide several basic attributes that other developers can view without needing to access the detailed implementation:      *   **Name:** The name of your service, typically derived from the component name but可自定义.     *   **Label:** A unique string uniquely identifying your specific deployment instance of the service within the platform.     *   **Endpoint:** The network-exposed address of the running service, including details on how to connect to it (e.g., protocol, host, port).     *   **Overview:** A brief description of the component, if provided by the developer during deployment.     *   **Version:** The version of the component file (e.g., `v1`), indicating the specific build promoted.     *   **Major Version:** The main version number (e.g., `v1` in `v1.2.3`), indicating the primary version series.     *   **API definition:** If your service exposes a network-readable endpoint (typically HTTP or GRPC), the Marketplace entry will represent this as a API, providing its unique identifier.      These details in the Marketplace are intended to be sufficient for other developers to understand what the service does (based on the overview) and how to potentially use or integrate with it (via the endpoint). More specific configuration details or source code would typically reside in the component's entry in the Marketplace, separate from the service entry itself."
"This is how the Marketplace and service versioning work:      *   **Marketplace Listing:** The Marketplace displays services per their major version. For example, if you have both `v1` and `v2` of your service deployed, the Marketplace will show `v2`. This `v2` listing represents the latest backward-compatible version.     *   **Semantic Versioning:** Services are deployed with a specific semantic version (e.g., `v1.2.3`). The major version (e.g., `v1` or `v2`) is derived from this.     *   **Deploying Updates:**         *   When you deploy a *new minor version* (e.g., deploying `v1.3.0` after `v1.2.5`), the corresponding major version (`v1`) in the Marketplace is updated to represent this new `v1.3.0` deployment.         *   When you deploy a *new major version* (e.g., deploying `v2.0.0` after `v1.x.x`), a *new major version* listing is created in the Marketplace for `v2`.     *   **Automatic Routing for Connected Components:** Crucially, when another component is connected to your service using the Marketplace catalog, it links to a *specific major version*. If you deployed a new *minor version* within that same major version range, the Marketplace routing mechanism will *automatically route traffic* to the *new minor version*.      In summary, components connected to your service via the Marketplace will automatically benefit from *minor version updates* (bug fixes and backwards-compatible changes) without requiring manual configuration changes in the connecting component. Major version updates, while requiring visibility in the Marketplace catalog, still benefit from automatic traffic routing to the latest within that range at the time of connection."
"The platform uses a "build once, deploy many" strategy, which is designed exactly for this scenario. Here's how it works:      1.  **Build Immutability:** When you build your application component from source code (or a Dockerfile), the platform creates a single, immutable container image artifact for that specific version (like a Git commit). This image is the exact same regardless of which environment it will eventually run in.     2.  **Configuration Separation:** You maintain two distinct sets of configurations: one for your application components themselves (like the image pulled from Docker Hub) and one for the *environments* you deploy to.     3.  **Environment-Specific Configurations:** Each environment (e.g., development, production) has its own set of configurations and secrets that are *not* baked into the built container image. These include things like database connection strings, API keys, and other context-specific data.     4.  **Runtime Injection:** At runtime, when you deploy or promote your component to a specific environment, the platform takes the single, built container image and injects the configuration and secrets specific to *that* environment into it.      This strategy ensures that you are testing and promoting the *exact same* application code (the built image) across your different environments. Any differences in behavior due to external dependencies are handled by the injected environment-specific configurations, keeping the core application logic separate from the deployment context."
"To update the `UserAuthService` component in the production environment to its `v1.6` version, you should leverage the platform's officially supported deployment strategies, specifically designed for different environments like production.      Here's the steps you would typically take:      1.  **Build the Image:** Ensure that the `v1.6` version of your `UserAuthService` component has been built and potentially pushed to a registry. The platform links build statuses back to the original commit.     2.  **Deploy the Component (Production):** Instead of manually deploying or promoting, you would go to the component's details page in the platform's management console. Look for the "Deploy" or "Promote" option specifically associated with the *production* environment. This will trigger a deployment workflow that takes the latest available image for `v1.6` (or you can select a specific commit if needed) and deploys it to the production environment.     3.  **Handle Environment-Specific Configuration:** During the deployment or promotion to production, the platform allows you to provide or link to configuration secrets and configurations specific to that environment. These environment-specific settings are injected into your component at runtime. Make sure these production configurations are correct before initiating the deployment.     4.  **Observe and Validate:** After the platform handles the deployment, you can observe the logs, monitor metrics, and perform tests (if enabled for production) to validate that the `v1.6` version of `UserAuthService` is running correctly and smoothly transitioned in the production environment, incorporating any necessary production-specific settings.      This approach ensures that the deployment process is robust, testable (you've tested `v1.6` in development), and benefits from the platform's understanding of environment specifics and rolling updates, helping minimize disruption during the switch."
"Choreo employs a "build once, deploy many" strategy for managing components across environments. This means that when you build your application component from source code in a specific environment (like development), the platform creates a single, immutable container image artifact. This same container image is then promoted and deployed to higher environments (like staging or production) where it gets deployed.      The main advantage of this "build once" approach is significant consistency and reliability. By building the artifact only once for a given commit, you eliminate the risk of subtle differences introduced by building the same code multiple times. The same tested and verified image that worked in development is used in production, ensuring that the behavior of your application remains consistent across its lifecycle, enhancing predictability and confidence in your releases."
"Choreo effectively manages this by using distinct "environment configurations" for each specific environment you have (e.g., development, production). At its core, the building and deployment process in Choreo are deeply linked to these environment configurations.      Here's how it works:      1.  **Separation of Code and Configuration:** Your service component's source code and the associated CHoreo components are independent of the environment details. The environment configurations are separate entities that you manage specifically for each environment.     2.  **Environment Configuration Storage:** When you create or promote an environment (like development or production), you provide or upload the necessary details for that specific environment within Choreo's interface. This information is stored securely, typically in a configuration vault linked to that particular environment.     3.  **Runtime Injection:** During the build process for your component, Choreo takes the built container image (which is environment-independent) and combines it with the environment configurations specifically defined for that target environment. This combination is then deployed to the runtime associated with that environment.     4.  **Runtime Read-Only Mount:** At runtime, the application container in your component receives the configurations for the specific environment as a read-only file system mount. Your application code reads this mounted configuration at startup to establish connections, set up resources, etc.      This mechanism ensures that while you can test your component in different environments using the same built image, it behaves correctly because it uses the right, environment-specific configuration details which are injected securely at runtime. You don't need to modify or rebuild your source code for each environment; just update the configurations provided for that environment."
"There are two main ways you can trigger a build process for your component:      1.  **Manually:** You can initiate a build at any time by going to the Build page for your component and clicking the "Build Latest" button. This is useful when you want to build a specific version (like a minor update within the same major version) or test a changeset before it's automatically promoted.     2.  **Automatically on Commits:** For components configured to use this method, a build pipeline is set up. Whenever a new commit is pushed to the connected Git repository (specifically, to the default branch like `main` or `master`), the platform automatically triggers a build. This ensures that a container image is created and pushed to the registry for each code update."
"The automatic build failure you're encountering is likely due to the platform's build strategy, which is `canary`. This strategy is designed to strictly enforce that configuration changes trigger a build.      Here's the breakdown:     *   Ballerina components are built by running the `ballerina build` command.     *   The platform uses two main types of builds: `normal` and `canary`.     *   A `canary` build is specifically triggered when configurations or secrets change and are incorporated into the build process.     *   When the platform encounters a build with configuration changes (as in your case), it proceeds with a canary build.     *   If there are issues in the Ballerina code that prevent it from building successfully when the configurables are applied (like syntax errors or runtime issues), the canary build will fail.     *   This behavior is intentional because it stops the deployment of potentially faulty code caused by configuration changes, promoting a "build once" policy for config updates.      In essence, the failure you see is the platform firmly enforcing the canary build strategy in response to your configuration changes in the Ballerina code, highlighting that configuration incorporation into the build itself can make the image unsuitable if the code isn't compatible."
"Absolutely! The standard flow for a "build once, deploy many" strategy in Choreo involves using environments to manage your application's lifecycle.      Here's how it typically works:      1.  **Linking Code and Building:** When you link a code repository to a component, Choreo automatically sets up a CI/CD pipeline. The first trigger for this pipeline is a commit to the linked branch (usually `main` or `master`). This trigger initiates a build process. During this build, Choreo takes the code from a specific commit, builds a container image from it, runs security scans, and pushes the image to a container registry. This image is built only *once* for that specific commit.     2.  **Deploying to Environments:** Once the image is built and pushed, you can proceed to deploy and promote that *same* image to your initial environment, typically 'development'. From there, you can effortlessly deploy the *exact same* image with its associated configurations to higher environments like 'production'.     3.  **Managing Environment-Specific Settings:** The key to deploying the *same* built image to different environments lies in managing environment-specific configurations and secrets. These are maintained separately within Choreo for each environment (e.g., 'development', 'production'). These values are injected into your application at runtime. This ensures that while the *code and the resulting container image* remain identical across environments, the behavior can be customized based on the environment's specific needs, such as database connection strings or API keys."
"Choreo is designed to work effectively with pre-built container images, which aligns perfectly with your existing CI pipeline that generates standardized Docker images. Here's how you can leverage Choreo for your Continuous Deployment (CD) needs, manage environment-specific configurations, and ensure zero downtime during deployments:      *   **Using Choreo with Pre-built Images:** You can enable the "Use external Docker registry" option within the Chopstick configuration for your component. This allows you to upload the Docker images produced by your CI pipeline to a external registry (like Docker Hub or an internal private registry) and then trigger deployments from there via Choreo.     *   **Handling Environment-specific Configurations:** Choreo excels at managing this. You can define separate "Environment connections" for each of your dev, staging, and production environments. These environment connections store environment-specific details, such as database connection strings, API keys, and other parameters, which are encrypted for security. These values are injected into your component at runtime. When you deploy or promote your component to a specific environment, it uses the configurations and secrets associated with *that* environment from the Environment connection.     *   **Achieving Zero Downtime Deployments:** Choreo supports rolling updates, which is the key to zero downtime deployments. When a new version of your component (containing the latest image and its associated environment configurations) is deployed to an environment, Choreo handles starting the new version of the component *before* shutting down the old one. This ensures that traffic continues to be routed through the newly deployed, healthy instance without interruption.      In summary, you can integrate your existing CI process with Choreo by using the external registry feature for deployment. Choreo's environment connection feature will handle the separation and injection of environment-specific configurations. And, by using rolling updates for deployment within each environment, you can achieve the required zero downtime during updates."
"The core strategy for moving your application components between environments is called "build once, deploy many." This means that when you build your component from a specific version of your code (a Git commit), the platform creates a single, immutable container image. This same image is then promoted and deployed to subsequent environments (like staging and production) after it has been tested in lower environments (like development).      Regarding the environment-specific settings (known as configuration secrets), the platform stores these separately from your source code and the built container image. These secrets are dynamically injected into your component at runtime when it starts up. This ensures that while the core application code and the built image remain the same across environments, the behavior can be customized based on the specific settings defined for each environment (e.g., database URL for production vs. development). This strategy promotes consistency, security, and easier management of environment-specific configurations."
"When you enable "Auto Build on Commit" for your component and push to the main branch, it triggers the platform's automated build process. This process compiles your source code into a container image and pushes this image to a container registry (either a platform-managed one or your own in a private setup). The "Auto Deploy on Build" setting then takes the newly built image and deploys it to the 'Development' environment.      The sequence for getting code to 'Production' from 'Development' is called "promotion". The platform allows you to define environments like 'Development', 'Staging', and 'Production' with their own isolated configurations (like API keys with restricted access). The process of promoting a component involves deploying an image from a lower environment (like 'Development') to a higher environment (like 'Production'). During this promotion, the configuration settings specific to the 'Production' environment are securely injected into the running component. So, while the same built container image goes to both 'Development' and 'Production', it's the combination of the image and the environment-specific configuration that gives the component its unique behavior in each environment. To initiate promotion, you typically go to the component's management section and trigger the promotion action for a specific build version that exists in the lower environment."
"To monitor and manage your scheduled task components, you can utilize the "Execute" page associated with that component. Specifically, to see the execution history for a particular day, you should look for the option named "Yesterday". Clicking on "Yesterday" will display the details of the task execution that occurred on the previous calendar day. This allows you to easily verify the success or failure of your daily task without having to manually search through recent executions."
"When a manual task component fails, the task execution monitoring screen provides detailed insights into the failure cause. Specifically, it offers two primary reasons for failure:      *   **Retry Policy Exhausted:** This reason appears if the task failed because it hit a configured retry limit. The platform allows you to set a number of automatic retries for transient errors. If all these attempts fail, the retry policy is exhausted, and this reason will be given.     *   **Manual Task Failed:** This is the reason given when the failure is due to an error occurring during the actual execution of the task. This could be due to a scripting error, a dependency issue, or any other problem that required human intervention.      By reviewing the "Failure Reason" provided for the specific failed execution, you can quickly understand whether you need to adjust your retry strategy or investigate the cause of the problem during the task's execution. The monitoring interface also links directly to the definition of the component and previous successful executions, aiding in your troubleshooting process."
"The system employs a strategy called "rolling update," which is designed to minimize disruption for your users when updating your service.      Here's how it generally works:      1.  When a new version of your service component is deployed (either manually triggered or as part of a promotion), the platform doesn't immediately route traffic to this new version.     2.  Instead, it starts by initializing the new version alongside the currently running (old) version.     3.  Once the new version has been successfully initialized and is ready to handle traffic, the system gradually shifts the incoming traffic from the old version to the new one.     4.  Only after the traffic has been successfully switched over to the new version is the old version shut down.      This process ensures that at no point during the update is there a lack of service availability for your users. The traffic is smoothly redirected during the switch, providing a seamless experience and helping to catch and mitigate any issues with the new version before affecting users."
"To effectively leverage the zero-downtime deployment capability and ensure reliability, you should actively enable and utilize the "Rolling Update" strategy within your deployments. This strategy is specifically designed to achieve seamless transitions by updating the minimum number of users at a time. Additionally, you should perform thorough testing, ideally in a staging environment with a "Rolling Update" enabled, to identify and fix any issues in the deployment process or application behavior before impacting live users. Observing the deployment logs and monitoring metrics are also crucial steps to quickly detect and address any problems that do arise during the deployment, allowing you to roll back if necessary. By enabling Rolling Update and complementing it with testing and monitoring, you can promote confidence in the zero-downtime mechanism."
"The platform provides a robust solution for managing service-to-service and service-to-external dependencies called "Connections". Its core principle is **Separation of Configuration and Code**. This means you do not include connection details directly in your microservice's source code or configuration files.      Here's how it works:     *   You create Connections within the platform's Marketplace.     *   When you need to use a Connection in a component (like a microservice), you reference it *by its ID* (or name) in the component's configuration or code.     *   The platform then dynamically injects the actual connection details (like API endpoints or credentials) into your component at runtime.     *   Crucially, these connection details are managed and stored separately from your source code in a secure vault.     *   Importantly, the same Connection can be used across different environments, and the platform allows you to maintain environment-specific configurations for it. This means the *ID* of the Connection remains the same, but the * injected values* can vary based on the environment, ensuring your service ties to the correct external service per deployment stage.      This approach guarantees that sensitive connection details are never hardcoded or exposed in your build artifacts. They are resolved only when your service is running in a specific environment, ensuring security and allowing for flexible deployment across different scenarios."
"Based on your scenarios, you should set up Connections as follows:      *   For the **shared logging service** accessed by *all* components in the project: You should create a **Project Connection**. This type of connection is specifically designed for services and resources that multiple components within the same project need access to. Whether it's OAuth, basic auth, or API keys, the credentials are managed at the project level, allowing all consuming components to leverage the same Connection.     *   For the **legacy system integration** used by *one specific microservice*: You should create a **Component Connection**. This is used when a *single* component needs access to a external service, and you can provide dedicated credentials (like an endpoint and API key) for that specific component's consumption. This keeps the connection configuration isolated from other components.     *   For the **internal API consumed by two components** using **OAuth security**: You should again use a **Component Connection**. While both components are consuming the same *endpoint* via OAuth, each of your two components will typically need its own individual OAuth application or client ID/secret. A Component Connection allows you to associate the shared endpoint with separate credentials for each consuming component, ensuring end-to-end security and separation.      In summary, use **Project Connections** for shared resources accessed by multiple components within a project, and use **Component Connections** for unique resources accessed by a single component, including when leveraging OAuth security on a shared endpoint but requiring individual consumer credentials."
"A 'Project Connection' and a 'Component Connection' primarily differ in their scope and usage:      *   **Component Connection:** This type of connection is established between two specific components within the same project. It's used when one component needs to access resources (like another component or external services) that are deployed *within the same project*. Communications using Component Connections are end-to-end encrypted and can leverage features like secrets management. You would typically use a Component Connection for connecting a front-end service to a back-end service both within your project.      *   **Project Connection:** A Project Connection, on the other hand, is designed for accessing resources that are available *beyond* the boundaries of a single component, most commonly external resources like databases, message queues, or third-party SaaS applications. It's specifically provided for consumption by *any component within the project*. In your case, creating a Project Connection to the external database is ideal because:         *   **Reusability:** Any service within your project can effortlessly establish a connection using this Project Connection ID and associated credentials.         *   **Ease of Management:** You configure the connection point once for the project, and all components utilizing it can benefit from the same connection details and potentially shared security groups or networks.         *   **Applicability:** Since external database credentials and connection details apply to all consumers within the project, a Project Connection simplifies the setup and ensures consistency across your application components.      In summary, you use a Project Connection when you have an external resource that multiple components in your project need access to, as it facilitates easy reuse and management compared to creating individual Component Connections for each consumer."
"When you create a Project Connection to an internal service using OAuth, the platform shares the OAuth application, including its client ID and client secret, across all components within that specific project. To use this shared OAuth application from your microservice component, you need to expose these credentials as configuration values. This exposes the connection details in a way that your microservice's code can consume them, allowing you to programatically establish the OAuth authentication when invoking the dependent service. You manage and view these shared secrets at the project level on the Config page."
"You should leverage the platform's capability to manage connections centrally, specifically by configuring a single connection component for the shared database, and then sharing this connection component's details (typically connection IDs) among your microservices.      Here's why this is the recommended approach:      *   **Reusability and Simplification:** Instead of configuring the same database credentials multiple times for each of your microservices, you configure them once within a single, defined connection component. This reduces the risk of error and ensures consistency across all services using that connection.     *   **Efficiency:** When a microservice references the shared connection component, it doesn't need to reinstantiate the connection logic or manage the credentials itself. The platform handles the sharing of the connection details (often via environment variable injection based on the connection ID) directly into the microservice's runtime.     *   **Easy Maintenance:** If the database credentials or endpoint change, you only need to update the configuration of the single connection component. All microservices utilizing that component will automatically benefit from the updated connection details without requiring individual changes or deployments for each service.     *   **Best Practice Alignment:** This approach aligns with the platform's principle of "configuration as code" and the model-based approach to managing dependencies and environmental information for your components."
"The platform employs a runtime injection mechanism to deliver the actual parameter values associated with your Connection or Kappa function configuration to your service component. Here's how it works and its primary advantage:      *   **Runtime Injection:** When your component is deployed and starts running, the platform dynamically injects the parameter values, mapped as environment variables, into the component's container at runtime. This means your application code reads these values directly from the environment variables once it is executing.     *   **Main Advantage:  Decoupling Configuration from Code:** The core benefit is significant decoupling between your service component's source code and its external dependencies (like database credentials, API keys, etc.). Your code doesn't contain hardcoded values. Instead, it relies on environment variables, which the platform manages and injects securely. This approach promotes:         *   **Flexibility:** You can test different environments (development, production, etc.) without changing your code, as the platform provides the correct values for each environment at runtime.         *   **Security:** Sensitive or changing configurations are not embedded in your source code repository. They are managed within the platform's configuration settings.         *   **SIMPLICITY:** Your code becomes cleaner and more portable, as it doesn't need to handle configuration details itself. The platform handles the secure delivery of these values when the component runs.         *   **Consistency:** Ensures that the exact same built container image is deployed across all environments, with the correct values injected based on the environment configuration."
"Absolutely! In a cloud-native platform's architecture, the "Control Plane" and the "Data Plane" have distinct roles:      *   **Control Plane:** This is the brain and management layer of the platform. It's where you interact to configure the platform's setup, manage users and organizations, control access permissions, and oversee the deployment and management of applications *before* they run. Typical activities include:         *   Managing the platform's configuration and setup.         *   Handling user administration, including organizations and permissions.         *   Coreching and managing the "how" of deployment processes for applications.         *   Controlling system components and the overall runtime environment.         *   It generally doesn't directly run user applications or customer data.      *   **Data Plane:** This is the engine room where your applications actually run and live. Think of it as the network of clusters (or isolated environments) that host your software components. Its primary functions are:         *   Running your deployed applications and associated services.         *   Storing and managing user data and application runtime information.         *   Providing the runtime environment for your code.         *   Handling infrastructure tasks specific to running applications, like pod scheduling.      In essence, the Control Plane manages the *how* (deployment, governance), while the Data Plane handles the *what* (execution of applications and processing of user data). Both parts together form the complete runtime environment for your cloud-native applications."
"The platform is designed with a "customer owned" model, specifically addressing stringent data residency and privacy concerns like yours. Under this model, your organization owns and manages the infrastructure where the platform's runtime components (like applications and services) are deployed. The key innovation is that the platform's configuration and orchestration logic are hosted as a SaaS layer *within your own infrastructure*.      This architecture implies that you do not need end-to-end dedicated network connectivity from your application code to the platform's SaaS management layer. Your browser-based interaction with the platform's management console and API orchestrations occurs *within your own network*. The runtime traffic (your application requests, etc.) goes to where your application code is deployed. The SaaS management layer merely provides the configuration and coordination signals necessary for the runtime components within your infrastructure.      In essence, the SaaS aspect applies to the *management* of your deployed applications *in* your infrastructure, not to the actual runtime traffic itself. This allows you to keep sensitive data and workloads within your controlled environment while still benefiting from a modern, managed CI/CD pipeline and resource orchestration within your chosen boundaries."
"The primary distinction lies in the underlying infrastructure model and level of isolation.      *   **Shared (Multi-Tenanted) Data Plane:** This model uses a single, pooled infrastructure layer that can be shared by multiple organizations or projects within a cloud environment. While your applications run on this shared infrastructure, it typically provides a higher degree of pre-configured security and compliance practices aimed at a wide audience. It's suitable for organizations or teams seeking simplicity, faster setup times, and leveraging pre-built configurations for common security standards without needing extensive custom infrastructure management.      *   **Dedicated (Private) Data Plane:** This model provides a single-tenant infrastructure layer that is exclusively used by a *single* organization or project. While it requires more initial setup and ongoing management overhead, it offers the highest degree of control, flexibility, and privacy. Organizations choosing this often have specific needs for:         *   **Compliance:** Require stringent data privacy or industry-specific regulations (e.g., GDPR, CCPA, GDPR within specific countries like the UK post-Brexit) that demand end-to-end control over their data and application runtime environment.         *   **Security:** Prioritize absolute data security and network isolation, potentially involving on-premises deployment or private clouds to meet internal security policies.         *   **Customization:** Need to deeply customize their CI/CD pipelines, infrastructure setup, or runtime environments to align with organization-specific standards, technologies, or architectures (e.g., running specific versions of Kubernetes, using certain security scanners, etc.).         *   **Control:** Want full visibility into and management of their own infrastructure resources, including potential integration with existing identity and access management systems.      In essence, the shared data plane is suited for standard use cases and teams prioritizing ease of use and quick deployment, while the dedicated data plane is geared towards organizations with unique requirements, higher security sensitivities, or specific regulatory mandates that benefit from exclusive infrastructure access and customization."
"When you set up a private data plane, you're responsible for the underlying infrastructure, including the Kubernetes clusters, container runtime, and essential system components. Think of it as having your own dedicated environment within the platform's infrastructure.      Regarding data privacy and security for configurations, secrets, and observability data in a private data plane:     *   **Configurations and Secrets:** These are stored securely within the platform's "vault" (a secure store). When you use a private data plane, the platform continues to use its own mechanisms for encrypting this data at rest and in transit. The data is stored within the private data plane itself, ensuring that sensitive configuration details and secrets for your applications and processes are not exposed outside your dedicated infrastructure.     *   **Observability Data:** Logs and metrics are collected and retained within the private data plane. The platform's "log warehouse" mechanism is used to handle this data, keeping it localized within your private environment. This approach guarantees that sensitive runtime data generated by your applications remains within your control and the dedicated infrastructure, aligning with compliance requirements for data locality. When you view this data through the platform console, your browser interacts directly with endpoints in your private data plane, further protecting the confidentiality of this sensitive information during viewing."
"A private data plane (PDP) is fundamentally different from a cloud data plane in that it provides dedicated infrastructure *for your sole use* within your own network or subscription, offering an added layer of data privacy and control. While multi-tenanted cloud data planes share underlying infrastructure between multiple organizations, a PDP is isolated for a single organization.      To run a private data plane, you would need to provide the **absolute minimum infrastructure components** on your end:     *   A Linux machine (or OS) with specific capabilities.     *   A Kubernetes cluster, either managed by you or supported by Alibaba Cloud.     *   A container registry.     *   A key vault (for managing secrets).      These components form the basis upon which the PDP software and your applications are deployed and run on your dedicated infrastructure."
"The control plane interacts with the private data plane *inbound*. This means the necessary traffic flows from the control plane (external) to the data plane (internal). If your corporate firewall restricts outbound traffic, you typically need to configure your security settings to permit inbound connections to the private data plane's specific endpoints. This ensures that the control plane can manage your data plane applications and operations without requiring the data plane to initiate connections outward."
"The observability architecture in a private data plane is designed with significant data storage limitations, particularly regarding logs. This restricts log data retention to a default of 7 days unless explicitly enabled and configured otherwise. For organizations like yours with strict data privacy concerns, this constrained log storage is a deliberate security measure. Combined with other security features of the private data plane observability, such as secure access and compliance with standards like GDPR and CCPA, the limited log retention serves to reduce the data exposed in its raw form, aligning with best practices for data minimization and confidentiality."
"Users access and view observability data, including logs and metrics, directly from their web browser via the browser-based Choreo Console. Technically, the necessary data endpoints are configured to be accessed "North-South," meaning the platform's UI (running in your browser) initiates the request to retrieve the data stored within the private data plane.      The benefit of this North-South data access model is significant privacy and security. Since the data remains confined within your own infrastructure (the private data plane), you avoid routing sensitive information through external systems. This aligns with data privacy regulations and organizational security policies by keeping data local and reducing potential points of data exposure during transit. The Choreo Console interacts with APIs *within* your data plane to fetch this data, ensuring it stays within your control and network boundaries."
"A private data plane is designed with your specific organization's compliance needs in mind, providing dedicated infrastructure for your sole use. This model offers enhanced data locality and privacy because:      *   **Dedicated Infrastructure:** Your private data plane runs on infrastructure owned by your organization or in a specific cloud subscription (in the case of a SaaS private data plane on platforms like Azure or GCP). This ensures that your application components and associated data are isolated from other tenants.     *   **Data Storage:** User data, including messages and tasks, along with operational data like analytics and logs, are stored in containers within your private data plane. Specifically, these data points are retained in:         *   Your own storage accounts (if using the Azure or GCP SaaS private data plane setups).         *   On-premises file shares or storage systems (if you host the private data plane yourself).     *   This deployment minimizes the number of hops and transfer points for your data, allowing it to stay within your controlled environment, which is crucial for meeting regulations like GDPR or CCPA that require data residency within a specific jurisdiction.      In essence, a private data plane gives you end-to-end control over the hardware and network infrastructure where your applications run and their data is stored, directly addressing the core concerns around data locality and privacy."
"Regarding security and network requirements for a private data plane, here are the key points:      *   **Traffic Security:**         *   **Incoming Traffic:** All incoming network traffic to the private data plane is restricted and secured using **HTTPS**. This applies to connections coming into the data plane.         *   **Internal Traffic:** End-to-end communication within the data plane itself is protected by **SSL/TLS**. This ensures that traffic moving between components内部的通信使用 SSL/TLS 进行保护，增强了数据传输的安全性.      *   **Network Connectivity and Security:**         *   The private data plane requires a **public internet connection** to establish contact with the platform's control plane. This is necessary for receiving updates, configurations, and commands. Traffic flowing from the control plane to the data plane is also required to be outbound over the public internet.         *   For enhanced security, especially in sensitive environments, you have the option to use a **private connection**. A private connection allows communication between the control plane and the data plane without involving the public internet. This is typically achieved using a dedicated site-to-site VLAN connection or a private endpoint, providing an added layer of security and data privacy.      These measures ensure that while your private data plane is isolated from public networks for sensitive operations, it can still integrate securely with the management system, and all internal communications are encrypted for data protection."
"There are three distinct management models available for a private data plane, providing different levels of control:      *   **WSO2 Managed (Infrastructure and Platform Components):** In this model, the platform provider (WSO2) is responsible for managing both the underlying infrastructure (like the Kubernetes clusters, etc.) and all the WSO2 platform components deployed on that infrastructure. You use the WSO2 management console provided by the platform provider to configure and manage your applications and associated resources within this model.     *   **Customer Self-Managed (Infrastructure), WSO2 Managed (Platform Components):** Here, your organization takes responsibility for the infrastructure itself (the Kubernetes clusters, etc.). You provide and maintain this infrastructure. WSO2 manages and deploys all the platform components onto the infrastructure you have provided. You would use the WSO2 management console to control your applications and configurations within this setup.     *   **Customer Self-Managed (Infrastructure and Platform Components):** This model gives your organization the greatest degree of control. You are responsible for both the infrastructure (providing and maintaining the Kubernetes clusters, etc.) and the platform components yourself. While you own and manage the infrastructure and software, you still benefit from the WSO2 deployment process and potentially some core platform capabilities."
"For the 'Customer self-managed' model, WSO2 provides two main sets of deliverables:      *   **Software and Artifacts:** WSO2 will deliver the installation packages, configuration scripts, and any required software components for the private data plane. This includes the core platform software and associated services.     *   **Setup and Configuration Support:** WSO2 will support your organization through the setup process, helping with the configuration of the data plane. They will provide guidance on setting up necessary components, integrating with external systems if needed, and configuring security settings.      Regarding operational responsibilities, while WSO2 provides the software and initial setup support, your organization will be responsible for:      *   **Infrastructure Management:** You own and maintain the underlying cloud environment or dedicated infrastructure where the data plane is deployed.     *   **All Operational Tasks:** This encompasses all aspects of running the data plane independently, including patching and updating the software components ( WSO2 recommends using automatic updates when possible), managing user accounts and permissions, monitoring system health and performance, and handling routine administrative tasks.     *   Your organization will need to have the necessary infrastructure, technical expertise, and processes in place to perform these operational tasks effectively."
"Deployment Tracks are essentially structured pathways designed to simplify and organize your application deployments. Think of them as organized lanes leading to your environment.      The main benefits they provide are:      *   **Structure and Organization:** They ensure that your application deployments follow a defined sequence, promoting an organized CI/CD flow.     *   **Clarity:** Unlike traditional methods, especially in complex multi-environment setups, Deployment Tracks clearly delineate what steps are required for a specific environment (e.g., development, production).     *   **Consistency:** They help maintain consistency across different deployments to the same environment by following the same set of steps and tests.     *   **Streamlined Promotion:** The platform allows you to effortlessly deploy an application component from a lower environment (like development) to a higher one (like production) by utilizing the deployments created in the lower environment.     *   **Reduced Errors:** By providing a structured approach, they can decrease the likelihood of human errors associated with manual deployment scripts or configurations.      In essence, Deployment Tracks aim to make the deployment process more reliable, manageable, and less error-prone compared to ad-hoc, manually managed deployment scripts."
"You can use Deployment Tracks with both your Git repository and your external Docker image production system by utilizing the "CD-Driven" strategy. This strategy allows you to source your deployments directly from a external Continuous Deployment pipeline, meaning the platform will take the images produced by your external CI system and deploy them via this track.      For API management, the platform utilizes a semantic version-based approach. When your service component exposes a API, you provide a `component.yaml` configuration file which defines a API definition (like `/v1/resources`), along with a desired major version (like `v1`). At runtime, the platform automatically generates and exposes two API endpoints for each API definition within a component:     *   The latest minor version: `<service-name>/<API-definition>,` (e.g., `my-service/v1/resources`)     *   The specific major version: `<service-name>/major-version/<API-definition>,` (e.g., `my-service/v1/my-resources`)      If you disable semantic-version-based intelligent routing for a particular API definition within your `component.yaml`, the platform will expose only the latest minor version endpoint for that specific definition, overriding the default behavior for all other APIs within the same component."
"A Deployment Track is a structured pathway designed for deploying services and APIs to a specific environment, such as development, staging, or production. It acts like a dedicated integration pipeline for that environment. This significantly improves the deployment process by organizing builds and deployments, ensuring consistency, and reducing errors associated with manual deployment steps.      There are two primary strategies for streamlined deployments using Deployment Tracks:      *   **Use Deployment Tracks directly:** You can choose to link your component's deployments directly to a specific Deployment Track. This approach is straightforward and allows you to use the Deployment Track's built-in integrations and automatically generated deploy scripts.     *   **Use Deployment Tracks with匠人模式 (Craftsman Mode):** If your component is being deployed using the匠人模式 (Craftsman Mode), you can link your component's deployments to a Deployment Track within that specific project. This allows you to take advantage of the Deployment Track's features while continuing to use the Craftsmen-based deployment process.      By using these strategies, you can leverage the structured approach provided by Deployment Tracks to ensure your components are consistently and reliably deployed to your target environments."
"To use a Deployment Track with images that are already in your container registry, you should enable the "Use your own registry" option when configuring the track. This approach allows you to deploy images sourced directly from your specified registry.      When you enable "Use your own registry," the platform requires two pieces of information from you:     *   The **Container registry URL** where your images are stored.     *   The **Registry credential** (either a username and password or an OAuth token) needed to access the repository within that registry.      With this configuration, the platform can link the deployment pipeline to your external registry. When you trigger a deployment or promotion via the track, it will retrieve the image(s) from the specified registry using the provided credentials and proceed with deploying those images to the configured environment."
"The platform supports intuitive major and minor versioning for your API deployments, designed specifically to manage updates smoothly for your consumers.      Here's how it works:     *   When you deploy or promote your API with a specific version (e.g., `v1.3`), the platform automatically updates the corresponding entry in the Marketplace.     *   Crucially, the Marketplace and service discovery are based on **major version formatting** (follows Semantic Versioning, e.g., `v1`, `v2`).     *   This means that if you deploy multiple minor versions within the same major version range (e.g., `v1.1`, `v1.2`, `v1.3`), the Marketplace will represent this as just `v1`.     *   Importantly, if a new minor version (or any subsequent minor version within the same major range) is deployed *after* an API consumer has initially connected to `v1`, the platform's "semantic-version-based intelligent routing" will automatically redirect the traffic from the consumer to the *newest* deployed minor version within that `v1` range (e.g., if they initially connected to `v1.2`, the platform will later route to `v1.3` without the consumer needing to change their endpoint).     *   This ensures that consumers automatically benefit from backward-compatible updates within their adopted major version without manual intervention, while still allowing them to explicitly discover and adopt new major versions (like switching from `v1` to `v2` if available) from the Marketplace."
"Yes, Deployment Tracks are specifically designed to handle this scenario by providing environment-independent builds and separate deployment pathways for different versions.      Here's how you can use Deployment Tracks for both your minor update and future major version development:      1.  **Deploying the `v1.6` Minor Update:**         *   You would continue using the existing Deployment Track, which is linked to the main `v1.x` branch (currently `v1.5`).         *   When the `v1.6` commit is merged into the main `v1.x` branch (or the `v1.6` specific branch is merged if you prefer merging directly to releases), the platform will automatically trigger a build.         *   This build, being part of the `v1.x` version, will be deployable to both your development and production environments within the deployment track for `v1.x`.         *   You can specifically deploy this latest `v1.6` build image to your production environment, achieving the minor version update without affecting the `v2.0` development.      2.  **Managing the `v2.0` Major Version:**         *   For the `v2.0` major version, you would create a *new* Deployment Track, specifically for the `v2.x` version range.         *   This new Deployment Track will link to the branch containing your `v2.0` development (e.g., a `v2.0` release branch or the `main` branch for `v2.x`).         *   Builds produced from this new `v2.x` Deployment Track will be considered `v2.0` versions.         *   You can use the platform's "Rolling Forward" strategy in the `v2.x` Deployment Track to manage deployments and rolling updates for your `v2.0` components once it's time to promote them.      In essence, you use the *existing* Deployment Track for the `v1.x` major version range to handle all future minor updates (like `v1.6`). You create a *new* Deployment Track specifically for the `v2.x` major version range to manage the significant changes and potentially different deployment strategies associated with a major version update. This allows you to keep your `v1.x` and `v2.0` versions isolated in terms of their deployment pipelines from this moment forward."
"An Endpoint in this context is a network-exposed function that originates from a deployed application component. Think of it as a specific network-visible point or service provided by that component. These endpoints are defined with details like their network name, the component they belong to, and attributes related to their network visibility (e.g., public, private).      Based on the information provided, two main types of components are designed to expose endpoints:      *   **Web Components:** These are typically web applications or services exposed over HTTP/HTTPS. A single web component deployment usually exposes one or more endpoints corresponding to its listening HTTP endpoints.     *   **Headless Services:** These are backend services typically consumed by other services or external systems, often exposing a single endpoint representing the service's network presence.      Other component types like scheduled tasks or internal services generally do not expose endpoints directly from their deployment."
"Once services are deployed, the platform uses the Endpoint concept as a key mechanism for management, governance, and external discovery.      Here's how it works:      1.  **Runtime Traffic Routing:** At runtime, the platform usesEndpoints to direct network traffic to your service components. A singleEndpoint is associated with one or more deployed component instances. When a service needs to be consumed, requests are routed through theEndpoint. This allows the platform to leverage mechanisms like intelligent routing, circuit breaking, and security filters directly from the Explorer interface on theEndpoint card.     2.  ** manh      Management:** The platform performs essential housekeeping tasks on the endpoints themselves, such as monitoring, logging, and managing the lifecycle (e.g., starting/stopping). These operations are targeted directly at the endpoint components.     3.  **Discovery and Exposure:** When your component is configured as a service to be consumed externally (or internally within the organization), the platform exposes itsEndpoint external IP. ThisIP is what other services or clients (human users, integrations, etc.) will connect to when trying to consume your deployed service. The platform also facilitates discovering these endpoints within the platform's console, allowing consumers to find and manage dependencies easily."
"Environments are dedicated, isolated spaces provided by the platform where you can deploy and run your applications. Think of them as distinct stages in your software delivery pipeline, such as `development`, `staging`, or `production`. Each environment offers its own set of resources and network visibility levels. Applications deployed in one environment cannot directly communicate with services in another environment as a security and isolation principle. This means you can test and develop your application in a `development` environment without it interacting with live production data or services until you explicitly deploy it to the `production` environment. This separation ensures that your production environment remains free from unintended external influences during testing."
"This platform is specifically designed to support the "build once, deploy many" strategy, which you've correctly described. Here's how it facilitates this approach, particularly with handling environment-specific configurations:      *   **Separation of Code and Configuration:** The platform achieves "build once" by separating the application code from environment-specific configurations and secrets. The build process creates a container image that is independent of the environment it will eventually run in. The configurations and secrets are handled separately for each environment.     *   **Configuration Management:** Environment-specific configurations and secrets are managed securely within the platform's configuration management features. These are typically stored encrypted and injected into your application at runtime.     *   **Injection at Runtime:** When you deploy or promote the built artifact to a specific environment, the platform dynamically injects the configurations and secrets associated with *that particular environment* into the running container. This keeps sensitive information out of your source code and ensures that the *same* built artifact can run in different environments with different settings.     *   **Consistency:** By building the artifact once and using the same image across all environments and injecting environment-specific configs at runtime, you achieve consistency in the application binary itself, reducing the risk of "works on my machine" issues related to build variations.      In essence, the platform allows you to build a single, immutable container image (the "build once" part) and then customize its behavior for each environment (the "deploy many" part) through configurable parameters injected during deployment."
"The platform uses an "Organization" structure specifically designed to address these concerns around user isolation and resource management across multiple teams.      Here's how it works:      *   **Logical Grouping:** An Organization acts as a logical container or boundary. You configure users and all your projects (which are collections of related services and applications) within a single Organization.     *   **Isolation Principle:** A key design concept is that users and resources belonging to one Organization are isolated from users and resources in another Organization. This means:         *   **User Isolation:** Users enrolled in one Organization cannot access projects or resources belonging to another Organization.         *   **Resource Isolation:** Services and applications deployed as APIs or web applications within one Project (belonging to an Organization) will have their network traffic restricted, preventing them from easily communicating directly with services in another Organization.     *   **Benefits for Multi-Team Work:** This structure is ideal for your scenario because:         *   **Compartmentalization:** Each team can have its own Project(s) within the Organization, containing their specific services and applications. Other teams' Projects and resources remain out of sight and inaccessible.         *   **Controlled Access:** User management and access permissions are managed at the Organization level. You can control which specific users or groups within an organization have developer, administrator, or viewer access to *any* project within that Organization.         *   **Security:** The isolated boundary prevents unintended access or interference between teams' deployments and operations.         *   When you create and manage your teams and their projects within this Organization context, you leverage this isolation to ensure your team members focus on their own work without unnecessary exposure to others', and your applications operate securely within their defined boundaries."
"A private data plane (PDP) is deeply integrated with your organization's structure. When you create a PDP, it becomes associated with a specific **Project** within your Organization. All components deployed on that PDP are then considered part of that Project. This association is fundamental for data privacy and containment, ensuring that:      *   Data and traffic within a PDP are strictly confined within the networks and security boundaries associated with your specific Organization.     *   The platform ensures logical isolation of resources between different Organizations.     *   Users and components within one Project (running on the PDP) cannot access resources in another Project (even if they are on the same PDP) unless explicitly allowed within the Project's security policies.      A private data plane offers guaranteed data privacy and containment for your organization's data by providing:      *   Dedicated infrastructure (either dedicated hardware or dedicated virtual clusters) for your organization's applications.     *   Network isolation: Traffic between your PDP components and the shared platform control planes is restricted, typically using mechanisms like VPC-vPC isolation.     *   Compliance with data locality requirements: The platform supports deploying resources within specific regions or even specific availability zones where your organization's data resides.      To function correctly and maintain communication with the platform's management layer for tasks like automatic updates, configuration, and monitoring, a private data plane requires **internet connectivity** to the public Internet. While direct consumer-facing traffic can be restricted at your boundary, the necessary management and update traffic needs this internet access. Once set up with internet access, the PDP operates independently of the underlying underlying infrastructure details, focusing on providing a consistent development and runtime environment for your organization's applications within your defined Project."
"When a new user joins your organization, their permissions to work within the platform, including access to specific services and projects, are typically managed through groups and roles.      Here's how it generally works:      1.  **User Addition:** When a new team member signs up or is invited, they become a user within your organization.     2.  **Adding to a Group:** The platform administrators (usually your organization owner or admin) will add this new user to one or more predefined groups. Groups are collections of users who typically share the same functional role or responsibility within the organization (e.g., Developer, Designer, Deployment Engineer).     3.  **Assigning Roles:** Each group is associated with one or more "roles." Roles define the specific permissions and capabilities granted to members of that group. For example, the 'Developer' group might be assigned the 'Developer' role, which grants permissions for coding, testing, and deploying components across all projects.     4.  **Inheritance:** Users automatically inherit the permissions associated with any groups they are added to. If a user is in multiple groups with overlapping roles, their permissions are effectively merged.      The fundamental building blocks for defining permissions and accessing resources are:      *   **Projects:** These are the primary logical isolation points. Services and components are deployed within a project. A user with access to a project can perform tasks like deployment, promotion, and viewing logs *within* that project.     *   **Environments:** Environments (like development, staging) are environments *within* a project where components can be deployed. Access to deploy or promote components typically requires permissions specific to a particular environment within a project.     *   **Components:** These are the individual services or applications deployed within an environment. Access to work on a component, like building or deploying it, requires permissions at the environment level within the project it belongs to.      So, while the user themselves is directly added to groups, it's the groups and the roles assigned to them that link the user to their specific permissions, typically scoped first to projects and then to environments and components within those projects."
"The platform defines two specific roles that align closely with the functional distinctions you described:      *   **Developer:** This role is designed for users who develop, build, test, and deploy cloud-native applications. Think of it as a "Developer" or "Developer/Engineer" role, suitable for developers focusing on writing code, using CI/CD pipelines, and managing their application components within the platform.     *   **Admin:** This role is intended for platform administrators and members of the organization who need to manage the infrastructure, governance, security, and other aspects of the platform itself, unrelated to the day-to-day development of applications. This includes tasks like user management, setting up projects and environments, managing secrets, and overseeing governance policies.      The key difference lies in their primary responsibilities: Developers work *with* the application code and associated components, while Admins manage the *environment* and resources *for* all users and components within the organization.      Regarding the deprecated role mentioned, the System Scientist role was previously available but has been replaced by the Developer role. The platform continues to allow users with the deprecated role to access and use the system scientist features. However, any new users or existing users adding the system scientist role in the future will automatically have the Developer role instead. This approach ensures that existing system scientists can continue their work while new adopters receive the updated, recommended role (Developer) with potentially enhanced capabilities or aligning better with current best practices."
"To locate your organization's unique "Organization ID" using the console, you should navigate to the **Settings** section. Specifically, you need to go to the **General** subsection within the Settings area. Once there, you will see a variable called `ORGANIZATION_ID`. Clicking on this variable will display its value, which is the unique identifier you are looking for for your particular organization."
"No, "Organization ID" and "Organization Handle" are not the same thing. They are distinct unique identifiers for an organization, but they belong to different scopes or parts of the platform's infrastructure.      *   The **Organization ID** typically refers to a identifier that is unique *within the platform* and is often used to identify an organization at a higher level or across the entire platform system.     *   The **Organization Handle**, on the other hand, is a unique identifier that is specifically tied to the **GitLab Compose project** associated with that organization. It is formatted as a combination of the project name and a resource path, uniquely representing the organizational context within the GitLab Compose multi-tenant architecture.      To retrieve the **Organization Handle**, you would typically look for it in the configuration or details section related to the GitLab Compose project setup for that organization, as it pertains specifically to its deployment environment within the platform hierarchy."
"The platform uses a hierarchy of groups to organize users and manage access to applications and resources. There are three main levels of groups:      *   **Organization:** This is the highest level. Users and all their projects belong to an Organization. Organizations act as logical containers for related users and resources, often corresponding to a single client company or organization.     *   **Project Area:** Project areas exist within an Organization and group together related Project Kits (groups of connected components). All components within a project area are deployed into a single Kubernetes namespace. Developers typically work within a project area.     *   **Project Kit:** A Project Kit is a single vertical application consisting of one or more components that are closely related (usually a frontend and one or more microservices). Components within a Project Kit are deployed into a single Kubernetes pod at runtime. A Project Kit always resides within a Project Area.      In terms of resource access, users and administrators primarily interact with Organizations. Projects and components within a Project Area are managed by project members. The Project Area level is where deployment namespaces are configured. And finally, components are managed and deployed at the Project Kit level. This hierarchy allows for effective isolation and management of resources at different scales, from the organization down to individual application components."
"The platform excels at managing this by separating your application's code from its environment-specific configurations and secrets. It uses a concept called "infrastructure injection," where essential details about the deployment environment (like the database connection string or API keys) are injected into your application at runtime. These environment-specific values are maintained separately for each stage (e.g., development, production).      This separation is crucial for a process called "build once, deploy many." Your application's code is built into a container image only once. This same image can then be deployed to different stages. The environment-specific configurations and secrets, which vary between stages, are injected when the component is deployed to a specific stage.      To prevent your development code from being deployed to production accidentally, the platform enforces a principle of "practical licked." This means that components deployed to higher environments (like production) are considered immutable. You cannot modify the code or configuration of a deployed component directly. If you need to update your application or introduce changes, you build a new container image with the updates and deploy it to the stage. This ensures that the production environment remains stable, and any change requires a deliberate deployment of the new image. The platform also helps manage this process securely and reliably."
